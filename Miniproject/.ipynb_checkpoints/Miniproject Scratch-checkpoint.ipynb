{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i genereate 10,000,000 data points using the generation model \n",
    "n_sample = 1000000\n",
    "gn = [np.random.normal(),np.random.normal(),np.random.normal()]\n",
    "data = []\n",
    "for idx in range(3,n_sample+3):\n",
    "    g = np.random.normal()\n",
    "    gn.append(g)\n",
    "    data.append(.1*g+.5*gn[idx-1]-.5*gn[idx-2]+.1*gn[idx-3]) # x_[n] = u_[n] + 0.8*x_[n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights: [-0.67776111 -0.41394865 -0.17928979]\n",
      "MSE: 0.35160180930486845\n"
     ]
    }
   ],
   "source": [
    "# the following code obtains the optimal \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "COV_X = []\n",
    "for three_sample_before, two_sample_before, one_sample_before, curr in zip(data[0:-3:], data[1:-2:], data[2:-1:],data[3::]):\n",
    "    vector1 = np.array([one_sample_before, two_sample_before, three_sample_before]) \n",
    "    vector2 = np.array([curr, one_sample_before, two_sample_before]) # for R\n",
    "    X.append(vector1)\n",
    "    y.append(curr)\n",
    "    COV_X.append(vector2)\n",
    "X = np.vstack(X)\n",
    "y = np.array(y)\n",
    "COV_X = np.vstack(COV_X)\n",
    "\n",
    "\n",
    "R = np.cov(COV_X.T)\n",
    "p = y.dot(X)/len(y)\n",
    "w = np.linalg.inv(R).dot(p)\n",
    "prediction = X.dot(w)\n",
    "print(\"Optimal Weights:\",w)\n",
    "error = y.dot(y)/n_sample - p.dot(w)\n",
    "print(\"MSE:\",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73500254  0.55186864  0.19778589]\n",
      " [-0.69549231  0.73500254  0.55186864]\n",
      " [-0.66702645 -0.69549231  0.73500254]\n",
      " ...\n",
      " [-0.99269385  0.66472571 -0.04344567]\n",
      " [ 0.82101343 -0.99269385  0.66472571]\n",
      " [ 0.06824042  0.82101343 -0.99269385]]\n",
      "[-0.69549231 -0.66702645  0.41163089 ...  0.82101343  0.06824042\n",
      " -0.87328169]\n",
      "[-0.67776111 -0.41394865 -0.17928979]\n",
      "[-0.76206241  0.06817991  0.60820424 ...  0.40543633 -0.26470522\n",
      " -0.20812823]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)\n",
    "print(w)\n",
    "pred = np.matmul(X,np.transpose(w))\n",
    "print(pred)\n",
    "optimal = calc_MSE(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal MSE: 0.3516025510794248\n",
      "Optimal SNR: 1.689031701807043\n",
      "(3,) (999997, 3)\n",
      "For BW: 1\n",
      "MSE= 0.5714396212726889\n",
      "Within .5dB? True\n",
      "SQNR: -1.9000735925677714 \n",
      "\n",
      "YES\n",
      "(3,) (999997, 3)\n",
      "For BW: 2\n",
      "MSE= 0.44448397283330027\n",
      "Within .5dB? True\n",
      "SQNR: -0.05167520370477453 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 3\n",
      "MSE= 0.3847529970696198\n",
      "Within .5dB? True\n",
      "SQNR: 0.8977529091942771 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 4\n",
      "MSE= 0.36958425618929625\n",
      "Within .5dB? True\n",
      "SQNR: 1.2041254275764248 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 5\n",
      "MSE= 0.3652350349363331\n",
      "Within .5dB? True\n",
      "SQNR: 1.3074655167237503 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 6\n",
      "MSE= 0.3632550510129529\n",
      "Within .5dB? True\n",
      "SQNR: 1.3526461061882187 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 7\n",
      "MSE= 0.36262585927996344\n",
      "Within .5dB? True\n",
      "SQNR: 1.3700137376668287 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 8\n",
      "MSE= 0.36231707017883763\n",
      "Within .5dB? True\n",
      "SQNR: 1.3783433501007503 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 9\n",
      "MSE= 0.3621672844250631\n",
      "Within .5dB? True\n",
      "SQNR: 1.3823835473771737 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 10\n",
      "MSE= 0.3621308623036991\n",
      "Within .5dB? True\n",
      "SQNR: 1.3839413702706402 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 11\n",
      "MSE= 0.3620939029588737\n",
      "Within .5dB? True\n",
      "SQNR: 1.3849319464902217 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 12\n",
      "MSE= 0.36207176479255154\n",
      "Within .5dB? True\n",
      "SQNR: 1.385468407012007 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 13\n",
      "MSE= 0.3620625213741821\n",
      "Within .5dB? True\n",
      "SQNR: 1.3857152815226592 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 14\n",
      "MSE= 0.3620574713196695\n",
      "Within .5dB? True\n",
      "SQNR: 1.385843516716404 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 15\n",
      "MSE= 0.3620546881903852\n",
      "Within .5dB? True\n",
      "SQNR: 1.3859106165842312 \n",
      "\n",
      "NO\n",
      "(3,) (999997, 3)\n",
      "For BW: 16\n",
      "MSE= 0.3620532390592777\n",
      "Within .5dB? True\n",
      "SQNR: 1.3859448265125571 \n",
      "\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    "#use quantize weight hw\n",
    "#when you do verilog code, assume physical hardware, so you need to store previous clk cycles\n",
    "W = [-.679, -.412, -.179]\n",
    "\n",
    "#must define W, and x\n",
    "\n",
    "def quantize(values,BW):\n",
    "    quant = np.minimum(np.round(np.array(values)*np.power(2.0,BW-1.0))*np.power(2.0,1.0-BW),1.0-np.power(2.0,1.0-BW))\n",
    "    return quant\n",
    "\n",
    "def calc_MSE(x,x_hat):\n",
    "    #here x is true values, x_hat is prediction\n",
    "        return np.sum(np.square(np.array(x) - np.array(x_hat)))/n_sample\n",
    "\n",
    "def evaluate_sqnr(data, dq,mserr):    \n",
    "    SNR = 10*np.log10(np.true_divide(np.sum(np.var(data)),np.sum(np.var(np.array(data) - np.array(dq)))+mserr))\n",
    "    return SNR\n",
    "\n",
    "def predict(wq,x):\n",
    "#     x_hats = list(x[0:3])\n",
    "\n",
    "#     for idx in range(3,n_sample):\n",
    "#         x_hats.append(np.dot(x[idx-3:idx][::-1],wq)) # the [::-1] reverses the list\n",
    "    x_hats = np.matmul(x,np.transpose(wq))\n",
    "    mse = calc_MSE(y,x_hats)\n",
    "   # print(wq, mse)\n",
    "    return mse\n",
    "    \n",
    "\n",
    "#first without quantizing:\n",
    "#mse_opt = predict(w,x)\n",
    "print(\"Optimal MSE:\",optimal)\n",
    "# sqnr_opt = evaluate_sqnr(x,data) #wait wouldn't this be zero which is infinity when dividing\n",
    "# print(\"optimal sqnr:\", sqnr)\n",
    "optimal_SNR = 10*np.log10(np.var(y)/optimal)\n",
    "print(\"Optimal SNR:\", optimal_SNR)\n",
    "\n",
    "\n",
    "\n",
    "def withindB(a,b):\n",
    "    return abs(a-b) <= abs(np.log10(.5))\n",
    "\n",
    "#now quantize for various bit precisions\n",
    "precisions = np.arange(1,17,1)\n",
    "\n",
    "MSEs = []\n",
    "for BW in precisions:\n",
    "    wq = quantize(w,BW)\n",
    "    dq = quantize(X,BW)\n",
    "    print(np.shape(wq),np.shape(dq))\n",
    "    MSE = predict(wq,dq)\n",
    "    print(\"For BW:\", BW)\n",
    "    print(\"MSE=\",MSE)\n",
    "    print(\"Within .5dB?\", withindB(MSE,optimal))\n",
    "    MSEs.append(MSE)\n",
    "    \n",
    "\n",
    "    sqnr = evaluate_sqnr(X,dq,MSE)\n",
    "    print(\"SQNR:\",sqnr)\n",
    "    print(\"YES\" if abs(sqnr-.5)>abs(optimal_SNR) else \"NO\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "#WAIT! SQNR IS SUPPOSED TO INCREASE AS PRECISION INCREASES! --> dbl check one of the prev hws as well, \n",
    "#but in quantization_notebook you can clearly see 16bit precision as higher sqnr than 4 bit\n",
    "#     print(\"Qunatization BW = \", BW)\n",
    "#print(predict(W))\n",
    "# print(quantize(data[:100],10))\n",
    "# print(data[:100])\n",
    "# dq = quantize(x,16)\n",
    "# print(dq,data[:10])\n",
    "# print(np.var(data),np.var(dq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.494275314307393\n",
      "[-0.67776111 -0.41394865]\n",
      "-0.4933838930348371\n",
      "[-0.15031085613312845, -0.8846703616903056, 0.7753793266432045, -0.5671195200292941, 0.2796068039413861, -0.6461037584555795, 0.2293888032230692, -0.12267838331428196, 0.43772829699252935, 1.1825931340004574, -0.8768908443862586, -0.8274557519150008, 0.2371256475436066, 0.6206658831075355, -0.043445665425472124, 0.6647257055827713, -0.9926938459425878, 0.8210134282652505, 0.06824041748188235, -0.8732816915946575]\n",
      "[-0.15031085613312845, -0.8846703616903056, 0.7753793266432045, -0.5671195200292941, 0.2796068039413861, -0.6461037584555795, 0.2293888032230692, -0.12267838331428196, 0.43772829699252935, 1.1825931340004574, -0.8768908443862586, -0.8274557519150008, 0.2371256475436066, 0.6206658831075355, -0.043445665425472124, 0.6647257055827713, -0.9926938459425878, 0.8210134282652505, 0.06824041748188235, -0.8732816915946575]\n",
      "[0.8210134282652505, 0.06824041748188235, -0.8732816915946575]\n",
      "[0.19778588689116874, 0.5518686425790891, 0.7350025393396982, -0.6954923128381378, -0.6670264479902963, 0.4116308902283441, -0.41258846044684655, 0.6030211720270823, -0.10538150011512896, 0.8454524372657894, -0.547942617302381, -0.5671391302063437, -0.7100958331718202, -0.41719777386439144, 1.4424751597443861, -0.6369670612665805, 0.12441067597014634, 0.011206940051199342, 0.2387521078931946, 0.45596374111059923, 0.07450833190463219, -1.0806968887498116, 0.645116925170049, 0.32058930131795305, -0.49764067799948275, -1.245285238413764, 1.4749996142938022, -0.9070679472699799, 0.17533208097672237, -0.46189016013911205, 0.23610458330243417, -0.7227989904667477, 0.677323020092867, -0.4280782075803103, 0.6048562734060967, -0.8284996604170873, 0.22204818761253434, -0.35429291986431755, 0.3546499512556715, -0.5666265522603937, 0.7746208087868263, 0.3302436385033638, -0.4818931186441542, -0.27021654204685763, -0.4303713327293065, 0.8965843392309232, -0.4239260502340154, 0.3191055866885251, -0.35226566504190393, 0.5521475925210017, -0.1620661043151731, 0.3150742520528919, -0.8231634069179941, 0.8761614684760523, -1.1061078848499695, 1.0016216388285628, 0.7547744595693837, -1.117892612915967, 0.6655671613737335, -1.561590520228924, 0.14789091401938853, 0.6853841505374747, -0.8151881256275774, -0.6564227050969793, 1.2771216324701655, -0.08051350592759365, -0.2915218974601043, -0.3587868676215682, 0.34288341787877274, 0.35063865296070773, -1.3770593026049516, 1.1211180218597347, -0.7013312622818333, 0.2817496190577434, 0.6946407025656993, -0.658158516857064, 0.008607695537347318, -0.18592797448997667, 0.5836961221188895, -0.24874251737370642, 0.020151049268496396, -0.2930213439760917, 0.6894483619079468, -0.06760764963571844, -0.38778375255112585, 0.8050234339807054, -0.47240623275802784, -0.3376823590453203, -0.04680369047802423, -0.13950303159582117, 0.8934833864399769, -0.2086551565893669, -0.17461703745549767, 0.6529336670208566, -0.8519760264189059, -0.7893563236017331, 1.040557115439616, -0.5509413216539406, 0.8993683752842279, -1.0581621221933937, 1.0253322881087135, 0.21486043778932512, 0.8846237737202306, -1.2585008236097326, 0.6702752417821967, 0.0610794530259813, -0.29809151687110447, -0.18267181254448142, 0.07213129172169612, -0.17352904261525204, 0.9725294141537246, -0.03536402796185327, -0.576786882015626, -0.06151560180477582, 0.7960822788719482, -0.33908634787740544, 0.46427213969939274, -0.45887176712185834, 0.04291694557662056, -0.22300277282599815, -1.0955277158458636, 0.4652294484570228, -0.352185807146956, 0.188612262102255, -0.44998620157069763, 0.6879199785822349, -0.9329988920162365, -0.33178555308140206, 0.4646073881387922, -0.0321687418195063, 0.02651719386215344, 0.6089134998808821, -0.7417191285713767, -0.17960613296590083, 0.8297078839409981, -0.6289601981718125, 1.010218752127289, -0.26295521167637026, 0.5168337503933934, -0.9017439093050953, 0.11818305450254821, 0.27199821673325003, 0.029871494448394015, -0.46855805058843036, -1.0805846863830597, 2.0223213835142553, 0.46329840608704614, -0.3150356637242326, 0.5083219686269028, -1.3750799604743291, 1.9506230380544567, -1.170479433634284, 0.1993223541675885, 0.04521740656796816, 0.17808305900519347, -0.18220568271106688, 0.11182555509921892, -0.8275782851089042, 0.7723291145407151, -0.016426314522825614, -0.5368577545630597, 0.5456852886972237, 0.19331430324657572, -0.34110376000765463, -0.9014126866298605, 0.7456994471401144, 0.25353570957962296, -0.6089225789344969, 0.07278962173813869, -0.2612010966222833, 0.09441170199242149, -0.044795637369412875, 0.11818957643478532, -1.1804084349719748, -0.027193576747970155, -0.7348722537910611, 1.4993078575701428, -1.3846684812943368, 0.053021814089896424, -0.4263443005861336, 1.4689452325908363, -0.8094973177614997, 0.553322731668333, -0.8371274937670409, -0.5324223611791822, 0.7555069790922344, 0.30942506262127184, -0.41837807044977726, -0.49638274696852114, 0.5469534493431266, 0.18647530309806504, -0.45038263928308814, 0.3554629143930568, -0.14277040283654324, 0.23296652080423116, -0.739738440630682, -0.1847655608419375, 0.47471230675882603, -0.06449463990890972, -1.0341828583217496]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(w,[0.19778588689116874, 0.5518686425790891, 0.7350025393396982]))\n",
    "print(w[0:2])\n",
    "print(0.197*-0.679 + 0.5518686425790891*-0.41286511 + 0.7350025393396982*-0.17928317)\n",
    "print(x[-20:])\n",
    "print(data[-20:])\n",
    "print(x[-3:])\n",
    "print(x[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17928979 -0.41394865 -0.67776111]\n",
      "[-0.67776111 -0.41394865 -0.17928979]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. , 1.5])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w[::-1])\n",
    "print(w)\n",
    "\n",
    "np.array(list(map(lambda f: f+1,[1,2,3])))\n",
    "\n",
    "t = np.array([1,2,3])\n",
    "t*float(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this prints data for system verilog format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
